{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Networks\n",
    "\n",
    "## 概要\n",
    "- Jupyter notebook上で一望できるくらい小さなニューラルネット(すぐ肥大化しそうな予感)\n",
    "- synthetic gradients試してみようと思って書きはじめた。勉強にもなるし\n",
    "- ReLU, MaxPooling, Linear, Conv2D, SoftmaxCrossEntropyをひとまず実装(バグあるかも)\n",
    "\n",
    "## 注意\n",
    "- Conv2Dは縁の処理をサボっているのでちゃんとしたフレームワークとは挙動が違うかも\n",
    "- あんまり速くない\n",
    "- Python2\n",
    "\n",
    "## TODO\n",
    "- BatchNormalizationの実装\n",
    "- weightのinitializeをもうちょっと丁寧に\n",
    "- gpu対応(私のPCにはNvidia GPUがないのでOpenCLを使う？)\n",
    "- RNNの記述法を考える\n",
    "- optimizerにmomentumを導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'activation'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(x, 0, dtype=x.dtype)\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        return gy * (self.x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_with_ndarray_index(ary, index, axis, inputs):\n",
    "    #ndarray_indexを使ってarrayに値を代入する。max_pooling用\n",
    "    shp = ary.shape\n",
    "    num_axis = shp[axis]\n",
    "    shp1 = reduce(lambda x,y:x*y, shp[:axis+1])/num_axis\n",
    "    shp2 = reduce(lambda x,y:x*y, shp[axis:])/num_axis\n",
    "    f_ary = ary.flatten()\n",
    "    f_ind = index.flatten()\n",
    "    f_inputs = inputs.flatten()\n",
    "    a_size = len(f_ary)\n",
    "    f_ary[f_ind * shp2 + np.rollaxis(np.arange(a_size).reshape(shp), axis)[0].flatten()] = f_inputs\n",
    "    return f_ary.reshape(shp)\n",
    "\n",
    "class MaxPooling2D(object):\n",
    "    \n",
    "    def __init__(self, k, stride=2, pad=0):\n",
    "        self.layer_type = 'pooling'\n",
    "        self.ksize = k\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        b, ch, h, w = x.shape\n",
    "        p = self.pad\n",
    "        k = self.ksize\n",
    "        s = self.stride\n",
    "        #padding input image\n",
    "        pH = h + p*2\n",
    "        pW = w + p*2\n",
    "        #cover all\n",
    "        pH += (s - (pH-k)%s) if (pH-k)%s != 0 else 0\n",
    "        pW += (s - (pW-k)%s) if (pW-k)%s != 0 else 0\n",
    "        self.pH = pH\n",
    "        self.pW = pW\n",
    "        _x = np.zeros((b, ch, pH, pW), dtype=np.float32)\n",
    "        _x[:, :, p:p+h, p:p+w] = x\n",
    "        #im2col\n",
    "        self.col = np.zeros((b, ch, k*k, ((pH - k)//s + 1), ((pW - k)//s + 1)), dtype=np.float32)\n",
    "        for i in range(0, pH - k + 1, s):\n",
    "            for j in range(0, pW - k + 1, s):\n",
    "                self.col[:, :, :, i/s, j/s] += _x[:, :, i:i+k, j:j+k].reshape(b, ch, k*k)\n",
    "        self.ind = np.argmax(self.col, axis=2) #hold max index\n",
    "        return np.max(self.col, axis=2)\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        b, ch, h, w = self.x.shape\n",
    "        p = self.pad\n",
    "        k = self.ksize\n",
    "        s = self.stride\n",
    "        #padding input image\n",
    "        pH = self.pH\n",
    "        pW = self.pW\n",
    "        #assign with pooling_index\n",
    "        gcol = np.zeros_like(self.col)\n",
    "        gcol = assign_with_ndarray_index(gcol, self.ind, 2, gy)\n",
    "        #col2im\n",
    "        gx = np.zeros((b, ch, pH, pW), dtype=np.float32)\n",
    "        for i in range(0, pH - k + 1, s):\n",
    "            for j in range(0, pW - k + 1, s):\n",
    "                gx[:, :, i:i+k, j:j+k] += gcol[:, :, :, i/s, j/s].reshape(b, ch, k, k)\n",
    "        return gx[:, :, p:p+h, p:p+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    \n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.layer_type = 'linear'\n",
    "        self.W = np.random.uniform(-1/math.sqrt(inputs), 1/math.sqrt(inputs), (outputs, inputs)).astype('f')\n",
    "        self.b = np.zeros((outputs), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        y = x.dot(self.W.T) + self.b\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x = self.x.reshape(self.x.shape[0], -1)\n",
    "        gx = gy.dot(self.W).reshape(self.x.shape)\n",
    "        self.gW = gy.T.dot(x)\n",
    "        self.gb = gy.sum(0)\n",
    "        return gx.reshape(self.x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Convolution2D(object):\n",
    "    \n",
    "    def __init__(self, in_ch, out_ch, k, stride=1, pad=0):\n",
    "        self.layer_type = 'convolution'\n",
    "        self.ksize = k\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.W = np.random.uniform(-1/math.sqrt(k*k*in_ch), 1/math.sqrt(k*k*in_ch), (out_ch, in_ch, k, k)).astype('f')\n",
    "        self.b = np.zeros((out_ch), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        b, ch, h, w = x.shape\n",
    "        p = self.pad\n",
    "        k = self.ksize\n",
    "        s = self.stride\n",
    "        \n",
    "        #padding input image\n",
    "        _x = np.zeros((b, ch, (h + p*2), (w + p*2)), dtype=np.float32)\n",
    "        _x[:, :, p:p+h, p:p+w] = x\n",
    "        \n",
    "        #im2col\n",
    "        self.col = np.zeros((b, ch, k, k, ((h + p*2 - k)//s + 1), ((w + p*2 - k)//s + 1)), dtype=np.float32)\n",
    "        for i in range(0, h + p*2 - k + 1, s):\n",
    "            for j in range(0, w + p*2 - k + 1, s):\n",
    "                self.col[:, :, :, :, i/s, j/s] += _x[:, :, i:i+k, j:j+k]\n",
    "        \n",
    "        #convolution\n",
    "        y = np.tensordot(self.col, self.W, ((1, 2, 3), (1, 2, 3))).astype(x.dtype, copy=False)\n",
    "        y += self.b\n",
    "        return np.rollaxis(y, 3, 1)\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        self.gW = np.tensordot(gy, self.col, ((0, 2, 3), (0, 4, 5))).astype(self.W.dtype, copy=False)\n",
    "        self.gb = gy.sum(axis=(0, 2, 3))\n",
    "        gcol = np.tensordot(self.W, gy, (0, 1)).astype(self.x.dtype, copy=False)\n",
    "        gcol = np.rollaxis(gcol, 3)\n",
    "        \n",
    "        #col2im\n",
    "        b, ch, h, w = self.x.shape\n",
    "        p = self.pad\n",
    "        k = self.ksize\n",
    "        s = self.stride\n",
    "        gx = np.zeros((b, ch, (h + p*2), (w + p*2)), dtype=np.float32)\n",
    "        for i in range(0, h + p*2 - k + 1, s):\n",
    "            for j in range(0, w + p*2 - k + 1, s):\n",
    "                 gx[:, :, i:i+k, j:j+k] += gcol[:, :, :, :, i/s, j/s]\n",
    "        return gx[:, :, p:p+h, p:p+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x -= x.max(axis=1, keepdims=True)\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x/np.sum(exp_x, axis=1).reshape(-1, 1)\n",
    "\n",
    "def softmax_cross_entropy(x, t):\n",
    "    log_y = np.log(softmax(x))\n",
    "    log_p = log_y[range(len(t)), t.ravel()] #Labelに対応する値が1になる→log(y)=0．不正解Labelに対して期待される確率は0であるからそれらは無視できる．\n",
    "    loss = - log_p.sum() / len(t)\n",
    "    \n",
    "    gx = np.exp(log_y) #というかこれはsoftmax(x)か。\n",
    "    gx[range(len(t)), t.ravel()] -= 1\n",
    "    gx *= loss\n",
    "    \n",
    "    return loss, gx\n",
    "\n",
    "def accuracy(x, t):\n",
    "    t_or_f = (np.argmax(x, axis=1)==t).astype('f')\n",
    "    return np.sum(t_or_f)/len(t_or_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(nnet, x):\n",
    "    for layer in nnet:\n",
    "#        print x.shape\n",
    "        x = layer.forward(x)\n",
    "    return x\n",
    "\n",
    "def backward(nnet, gy):\n",
    "    for layer in nnet[::-1]:\n",
    "        gy = layer.backward(gy)\n",
    "        \n",
    "def update(nnet):\n",
    "    lr = 0.0001\n",
    "    for layer in nnet:\n",
    "        if layer.layer_type not in ['activation', 'pooling']:\n",
    "            layer.W -= layer.gW * lr\n",
    "            layer.b -= layer.gb * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#あとでもうちょっと何とかする\n",
    "\n",
    "class MomentumSGD(object):\n",
    "    def __init__(self, net, learning_rate=0.0001, momentum=0.9):\n",
    "        self.net = net\n",
    "        self.lr = learning_rate\n",
    "        self.m = momentum\n",
    "        self.vs = [[np.zeros_like(layer.W), np.zeros_like(layer.b)] \\\n",
    "                        if layer.layer_type not in ['pooling', 'activation'] else None for layer in nnet]\n",
    "\n",
    "    def updates(self):\n",
    "        for v, layer in zip(self.vs, self.net):\n",
    "            if v is not None:\n",
    "                vW = v[0]\n",
    "                vb = v[1]\n",
    "                _vW = vW * self.m\n",
    "                _vW = _vW - self.lr * layer.gW\n",
    "                layer.W += _vW\n",
    "                v[0] = _vW\n",
    "                \n",
    "                _vb = vb * self.m\n",
    "                _vb = _vb - self.lr * layer.gb\n",
    "                layer.b += _vb\n",
    "                v[1] = _vb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Test\n",
    "- mnistで試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chainerのutilityをお借りしてmnistを読み込む\n",
    "#TODO: scipyのやつに書き換える\n",
    "import chainer\n",
    "train, test = chainer.datasets.get_mnist()\n",
    "\n",
    "X = np.zeros((60000, 1, 28, 28), dtype=np.float32)\n",
    "Y = np.zeros(60000, dtype=np.int32)\n",
    "X_test = np.zeros((10000, 1, 28, 28), dtype=np.float32)\n",
    "Y_test = np.zeros(10000, dtype=np.int32)\n",
    "for i in range(60000):\n",
    "    X[i] += train[i][0].reshape(1, 28, 28)\n",
    "    Y[i] = train[i][1]\n",
    "for i in range(10000):\n",
    "    X_test[i] += test[i][0].reshape(1, 28, 28)\n",
    "    Y_test[i] = test[i][1]\n",
    "    \n",
    "#[-1, 1]に正規化\n",
    "X -= 0.5; X_test -= 0.5\n",
    "X *= 2; X_test *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#モデルの準備\n",
    "#LeNet5 by LeCun. acc=0.99くらいまでは行けるとのこと。\n",
    "nnet = [Convolution2D(1, 20, 5),\n",
    "        MaxPooling2D(2, 2, 0),\n",
    "        Convolution2D(20, 50, 5),\n",
    "        MaxPooling2D(2, 2, 0),\n",
    "        Linear(800, 500),\n",
    "        ReLU(),\n",
    "        Linear(500, 10)]\n",
    "\n",
    "opt = MomentumSGD(nnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "type: train, sample: 10100, loss: 0.751559070587, accuracy: 0.7806\n",
      "type: train, sample: 20100, loss: 0.274144948292, accuracy: 0.9175\n",
      "type: train, sample: 30100, loss: 0.214468430519, accuracy: 0.9362\n",
      "type: train, sample: 40100, loss: 0.189391173267, accuracy: 0.945\n",
      "type: train, sample: 50100, loss: 0.164136211109, accuracy: 0.9542\n",
      "type: val, sample: 60000, loss: 0.129085744545, accuracy: 0.9618\n",
      "epoch: 1\n",
      "type: train, sample: 70100, loss: 0.137024268317, accuracy: 0.9701\n",
      "type: train, sample: 80100, loss: 0.131725745153, accuracy: 0.9607\n",
      "type: train, sample: 90100, loss: 0.123524282932, accuracy: 0.9635\n",
      "type: train, sample: 100100, loss: 0.117875331211, accuracy: 0.966\n",
      "type: train, sample: 110100, loss: 0.110841573501, accuracy: 0.9685\n",
      "type: val, sample: 120000, loss: 0.0954512225851, accuracy: 0.9719\n",
      "epoch: 2\n",
      "type: train, sample: 130100, loss: 0.0983075060606, accuracy: 0.9815\n",
      "type: train, sample: 140100, loss: 0.0997835698366, accuracy: 0.9723\n",
      "type: train, sample: 150100, loss: 0.086988818419, accuracy: 0.9756\n",
      "type: train, sample: 160100, loss: 0.0959940422535, accuracy: 0.9714\n",
      "type: train, sample: 170100, loss: 0.0872839926004, accuracy: 0.9745\n",
      "type: val, sample: 180000, loss: 0.0764120366424, accuracy: 0.9772\n",
      "epoch: 3\n",
      "type: train, sample: 190100, loss: 0.0808382610321, accuracy: 0.9869\n",
      "type: train, sample: 200100, loss: 0.0845193374157, accuracy: 0.9752\n",
      "type: train, sample: 210100, loss: 0.0772084295034, accuracy: 0.9787\n",
      "type: train, sample: 220100, loss: 0.0765222555161, accuracy: 0.9778\n",
      "type: train, sample: 230100, loss: 0.0707488009095, accuracy: 0.9803\n",
      "type: val, sample: 240000, loss: 0.0724916004717, accuracy: 0.9783\n",
      "epoch: 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-e1881240bd63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-f49342dbdce5>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(nnet, gy)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnnet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mgy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-172-a4833b48f5bb>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gy)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                  \u001b[0mgx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "N = len(X)\n",
    "N_test = len(X_test)\n",
    "batchsize = 100\n",
    "step = 100\n",
    "n_imgs_trained = 0\n",
    "\n",
    "for e in range(epoch):\n",
    "    print 'epoch:', e\n",
    "    sum_loss = 0.\n",
    "    sum_acc = 0.\n",
    "    perm = np.random.permutation(N)\n",
    "    \n",
    "    #train\n",
    "    for i in range(0, N, batchsize):\n",
    "        y = forward(nnet, X[perm[i:i+batchsize]])\n",
    "        loss, gy = softmax_cross_entropy(y, Y[perm[i:i+batchsize]])\n",
    "        acc = accuracy(y, Y[perm[i:i+batchsize]])\n",
    "        backward(nnet, gy)\n",
    "        opt.updates()\n",
    "        \n",
    "        n_imgs_trained += batchsize\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc\n",
    "        \n",
    "        if i%(batchsize*step)==0 and i!=0:\n",
    "            print 'type: train, sample: {}, loss: {}, accuracy: {}'.format(n_imgs_trained, sum_loss/step, sum_acc/step)\n",
    "            sum_loss = 0.\n",
    "            sum_acc = 0.\n",
    "    #val\n",
    "    sum_loss = 0.\n",
    "    sum_acc = 0.\n",
    "    for i in range(0, N_test, batchsize):\n",
    "        y = forward(nnet, X_test[i:i+batchsize])\n",
    "        loss, gy = softmax_cross_entropy(y, Y_test[i:i+batchsize])\n",
    "        acc = accuracy(y, Y_test[i:i+batchsize])\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc\n",
    "    print 'type: val, sample: {}, loss: {}, accuracy: {}'.format(n_imgs_trained, sum_loss/(N_test/batchsize), sum_acc/(N_test/batchsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
