{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "## Prepare Framework\n",
    "- 適当にニューラルネットを用意する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReLu(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'activation'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(x, 0, dtype=x.dtype)\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        return gy * (self.x > 0)\n",
    "\n",
    "class Linear(object):\n",
    "    \n",
    "    def __init__(self, inputs, outputs):\n",
    "        self.layer_type = 'linear'\n",
    "        self.W = np.random.uniform(-1/math.sqrt(inputs), 1/math.sqrt(inputs), (outputs, inputs)).astype('f')\n",
    "        self.b = np.zeros((outputs), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        y = x.dot(self.W.T) + self.b\n",
    "        return y\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        x = self.x.reshape(self.x.shape[0], -1)\n",
    "        gx = gy.dot(self.W).reshape(self.x.shape)\n",
    "        self.gW = gy.T.dot(x)\n",
    "        self.gb = gy.sum(0)\n",
    "        return gx.reshape(self.x.shape)\n",
    "    \n",
    "class Convolution2D(object):\n",
    "    \n",
    "    def __init__(self, in_ch, out_ch, k, stride=1, pad=1):\n",
    "        self.layer_type = 'convolution'\n",
    "        self.ksize = k\n",
    "        self.out_ch = out_ch\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.W = np.random.uniform(-1/math.sqrt(k*k*in_ch), 1/math.sqrt(k*k*in_ch), (out_ch, in_ch, k, k)).astype('f')\n",
    "        self.b = np.zeros((out_ch), dtype=np.float32)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        b, ch, h, w = x.shape\n",
    "        p = self.pad\n",
    "        k = self.ksize\n",
    "        s = self.stride\n",
    "        \n",
    "        #padding input image\n",
    "        _x = np.zeros((b, ch, (h + p*2), (w + p*2)), dtype=np.float32)\n",
    "        _x[:, :, p:-p, p:-p] = x\n",
    "        \n",
    "        #im2col\n",
    "        self.col = np.zeros((b, ch, k, k, ((h + p*2 - k)//s + 1), ((w + p*2 - k)//s + 1)), dtype=np.float32)\n",
    "        for i in range(0, h + p*2 - k + 1, s):\n",
    "            for j in range(0, w + p*2 - k + 1, s):\n",
    "                self.col[:, :, :, :, i/s, j/s] += _x[:, :, i:i+k, j:j+k]\n",
    "        \n",
    "        #convolution\n",
    "        y = np.tensordot(self.col, self.W, ((1, 2, 3), (1, 2, 3))).astype(x.dtype, copy=False)\n",
    "        y += self.b\n",
    "        return np.rollaxis(y, 3, 1)\n",
    "    \n",
    "    def backward(self, gy):\n",
    "        self.gW = np.tensordot(gy, self.col, ((0, 2, 3), (0, 4, 5))).astype(self.W.dtype, copy=False)\n",
    "        self.gb = gy.sum(axis=(0, 2, 3))\n",
    "        gcol = np.tensordot(self.W, gy, (0, 1)).astype(x.dtype, copy=False)\n",
    "        gcol = np.rollaxis(gcol, 3)\n",
    "        \n",
    "        #col2im\n",
    "        b, ch, h, w = self.x.shape\n",
    "        p = self.pad\n",
    "        k = self.ksize\n",
    "        s = self.stride\n",
    "        gx = np.zeros((b, ch, (h + p*2), (w + p*2)), dtype=np.float32)\n",
    "        for i in range(0, h + p*2 - k + 1, s):\n",
    "            for j in range(0, w + p*2 - k + 1, s):\n",
    "                 gx[:, :, i:i+k, j:j+k] += gcol[:, :, :, :, i/s, j/s]\n",
    "        return gx[:, :, p:-p, p:-p]\n",
    "    \n",
    "def softmax(x):\n",
    "    x -= x.max(axis=1, keepdims=True)\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x/np.sum(exp_x, axis=1).reshape(-1, 1)\n",
    "\n",
    "def softmax_cross_entropy(x, t):\n",
    "    log_y = np.log(softmax(x))\n",
    "    log_p = log_y[range(len(t)), t.ravel()] #Labelに対応する値が1になる→log(y)=0．不正解Labelに対して期待される確率は0であるからそれらは無視できる．\n",
    "    loss = - log_p.sum() / len(t)\n",
    "    \n",
    "    gx = np.exp(log_y)\n",
    "    gx[range(len(t)), t.ravel()] -= 1\n",
    "    gx *= loss\n",
    "    \n",
    "    return loss, gx\n",
    "\n",
    "def accuracy(x, t):\n",
    "    t_or_f = (np.argmax(x, axis=1)==t).astype('f')\n",
    "    return np.sum(t_or_f)/len(t_or_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    for l in nnet:\n",
    "        x = l.forward(x)\n",
    "    return x\n",
    "\n",
    "def backward(gy):\n",
    "    for l in nnet[::-1]:\n",
    "        gy = l.backward(gy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update():\n",
    "    lr = 0.001\n",
    "    for l in nnet:\n",
    "        if l.layer_type is not 'activation':\n",
    "            l.W -= l.gW * lr\n",
    "            l.b -= l.gb * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Test\n",
    "- mnistで試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "train, test = chainer.datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.zeros((60000, 1, 28, 28), dtype=np.float32)\n",
    "Y = np.zeros(60000, dtype=np.int32)\n",
    "for i in range(60000):\n",
    "    X[i] += train[i][0].reshape(1, 28, 28)\n",
    "    Y[i] = train[i][1]\n",
    "X -= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c0 = Convolution2D(1, 16, 4, stride=2, pad=1)\n",
    "c1 = Convolution2D(16, 32, 3, stride=1, pad=1)\n",
    "c2 = Convolution2D(32, 64, 4, stride=2, pad=1)\n",
    "c3 = Convolution2D(64, 128, 3, stride=2, pad=1)\n",
    "l4 = Linear(128*4*4, 256)\n",
    "l5 = Linear(256, 10)\n",
    "nnet=[c0,\n",
    "      ReLu(),\n",
    "      c1,\n",
    "      ReLu(),\n",
    "      c2,\n",
    "      ReLu(),\n",
    "      c3,\n",
    "      ReLu(),\n",
    "      l4,\n",
    "      ReLu(),\n",
    "      l5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0229326915741 0.0021875\n",
      "2.2967024231 0.1184375\n",
      "2.17276879191 0.2146875\n",
      "0.916777430773 0.718125\n",
      "0.529901775122 0.82625\n",
      "0.42349107936 0.87125\n",
      "0.387935250178 0.87625\n",
      "0.355191886574 0.8965625\n",
      "0.344978407845 0.9015625\n",
      "0.311198208258 0.9025\n",
      "0.301291378736 0.9053125\n",
      "0.253335500024 0.924375\n",
      "0.287057323605 0.9071875\n",
      "0.263761638887 0.92\n",
      "0.250971356928 0.9196875\n",
      "0.236316560432 0.9246875\n",
      "0.242422135696 0.928125\n",
      "0.238997259364 0.9290625\n",
      "0.220191886947 0.9346875\n",
      "0.00195239886642 0.0090625\n",
      "0.231725176089 0.9275\n",
      "0.221418728903 0.9315625\n",
      "0.181325034909 0.9490625\n",
      "0.19844683852 0.9353125\n",
      "0.202445771247 0.9359375\n",
      "0.181318219453 0.94375\n",
      "0.194040937833 0.9425\n",
      "0.172942409553 0.945625\n",
      "0.18240897391 0.9425\n",
      "0.191960714879 0.9434375\n",
      "0.159887112807 0.9534375\n",
      "0.165365229212 0.94875\n",
      "0.167279122509 0.9490625\n",
      "0.168200955205 0.9553125\n",
      "0.177439857051 0.95\n",
      "0.162232652716 0.951875\n",
      "0.173152746186 0.945\n",
      "0.166966315545 0.9459375\n",
      "0.00307523369789 0.00875\n",
      "0.142988890968 0.955625\n",
      "0.146332728378 0.956875\n",
      "0.162410121299 0.9478125\n",
      "0.175349306129 0.9465625\n",
      "0.153607324474 0.95625\n",
      "0.148765453994 0.9540625\n",
      "0.140346010178 0.9584375\n",
      "0.166581942793 0.9484375\n",
      "0.145636742637 0.9515625\n",
      "0.13032143889 0.9571875\n",
      "0.14114758892 0.955\n",
      "0.129706257544 0.9615625\n",
      "0.143984771259 0.9565625\n",
      "0.121515256409 0.961875\n",
      "0.12667072339 0.9640625\n",
      "0.124904957507 0.9596875\n",
      "0.130151394745 0.9590625\n",
      "0.138018310387 0.9578125\n",
      "0.000682234987617 0.01\n",
      "0.126626227722 0.9621875\n",
      "0.121289135702 0.96\n",
      "0.113067870643 0.9659375\n",
      "0.122418457968 0.9590625\n",
      "0.11453612769 0.96375\n",
      "0.114652749375 0.9646875\n",
      "0.119936727174 0.9625\n",
      "0.121711473698 0.9653125\n",
      "0.117384952465 0.9646875\n",
      "0.111965447394 0.9675\n",
      "0.111036860943 0.961875\n",
      "0.124574599238 0.9640625\n",
      "0.127224946506 0.960625\n",
      "0.113968434781 0.9640625\n",
      "0.117535176277 0.96375\n",
      "0.12201796148 0.96125\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "N = len(X)\n",
    "batchsize = 32\n",
    "\n",
    "for e in range(epoch):\n",
    "    sum_loss = 0.\n",
    "    sum_acc = 0.\n",
    "    perm = np.random.permutation(N)\n",
    "    for i in range(0, N, batchsize):\n",
    "        y = forward(X[perm[i:i+batchsize]])\n",
    "        loss, gy = softmax_cross_entropy(y, Y[perm[i:i+batchsize]])\n",
    "        acc = accuracy(y, Y[perm[i:i+batchsize]])\n",
    "        backward(gy)\n",
    "        update()\n",
    "        sum_loss += loss\n",
    "        sum_acc += acc\n",
    "        if i%(32*100)==0:\n",
    "            print sum_loss/100., sum_acc/100.\n",
    "            sum_loss = 0.\n",
    "            sum_acc = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
